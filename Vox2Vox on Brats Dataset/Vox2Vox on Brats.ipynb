{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "936a875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpolo\\anaconda3\\envs\\tf2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from Brats2020_Segmentation_Data_Generator import imageLoader\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import backend as K\n",
    "import random\n",
    "from glob import glob\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv3D, LeakyReLU, BatchNormalization, Concatenate, Activation, Dropout,Conv3DTranspose\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from IPython import display\n",
    "from tqdm.auto import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c94a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = \"BraTS2020_TrainingData/input_data_128/train/images/\"\n",
    "train_mask_dir = \"BraTS2020_TrainingData/input_data_128/train/masks/\"\n",
    "\n",
    "val_img_dir = \"BraTS2020_TrainingData/input_data_128/val/images/\"\n",
    "val_mask_dir = \"BraTS2020_TrainingData/input_data_128/val/masks/\"\n",
    "\n",
    "train_img_list=os.listdir(train_img_dir)\n",
    "train_mask_list = os.listdir(train_mask_dir)\n",
    "\n",
    "val_img_list=os.listdir(val_img_dir)\n",
    "val_mask_list = os.listdir(val_mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f443f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "train_dataset = imageLoader(train_img_dir, train_img_list, \n",
    "                                train_mask_dir, train_mask_list, batch_size)\n",
    "\n",
    "val_dataset = imageLoader(val_img_dir, val_img_list, \n",
    "                                val_mask_dir, val_mask_list, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ecdeaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images, target_images=train_dataset.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ee82610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 128, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7113fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 128, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64a2238d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input images: (1, 128, 128, 128, 4)\n",
      "Shape of target images: (1, 128, 128, 128, 4)\n"
     ]
    }
   ],
   "source": [
    "# Print shape information\n",
    "print(\"Shape of input images:\", input_images.shape)\n",
    "print(\"Shape of target images:\", target_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6625369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9da453c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    source_image= Input(shape=(128, 128, 128, 4))\n",
    "    target_image= Input(shape=(128, 128, 128, num_classes))\n",
    "    \n",
    "    cat= Concatenate()([source_image, target_image]) ## this makes the Gan conditional\n",
    "    d= Conv3D(64, kernel_size=4, strides=2, padding=\"same\", \n",
    "                     kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), \n",
    "                     use_bias=False)(cat)\n",
    "    d=LeakyReLU(0.3)(d)\n",
    "    d=Dropout(0.2)(d)\n",
    "    \n",
    "    \n",
    "    d=Conv3D(128, kernel_size=4, strides=2, padding=\"same\", \n",
    "                     kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), \n",
    "                     use_bias=False)(d)\n",
    "    d= BatchNormalization()(d)\n",
    "    d=LeakyReLU(0.3)(d)\n",
    "    d=Dropout(0.2)(d)\n",
    "    \n",
    "    \n",
    "    d=Conv3D(256, kernel_size=4, strides=2, padding=\"same\", \n",
    "                     kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), \n",
    "                     use_bias=False)(d)\n",
    "    d= BatchNormalization()(d)\n",
    "    d=LeakyReLU(0.3)(d)\n",
    "    d=Dropout(0.2)(d)\n",
    "    \n",
    "    \n",
    "    d=Conv3D(512, kernel_size=4, strides=2, padding=\"same\", \n",
    "                     kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), \n",
    "                     use_bias=False)(d)\n",
    "    d= BatchNormalization()(d)\n",
    "    d=LeakyReLU(0.2)(d)\n",
    "    \n",
    "    \n",
    "    \n",
    "    d=Conv3D(1, kernel_size=4, strides=1, padding=\"same\", \n",
    "                     kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), \n",
    "                     use_bias=False)(d)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return Model([source_image, target_image], d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a02667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                28, 4)]                                                           \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                28, 4)]                                                           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128, 128, 12  0           ['input_1[0][0]',                \n",
      "                                8, 8)                             'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)                (None, 64, 64, 64,   32768       ['concatenate[0][0]']            \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 64, 64, 64,   0           ['conv3d[0][0]']                 \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64, 64, 64,   0           ['leaky_re_lu[0][0]']            \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)              (None, 32, 32, 32,   524288      ['dropout[0][0]']                \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 32,   512        ['conv3d_1[0][0]']               \n",
      " alization)                     128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 32, 32, 32,   0           ['batch_normalization[0][0]']    \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 32, 32, 32,   0           ['leaky_re_lu_1[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)              (None, 16, 16, 16,   2097152     ['dropout_1[0][0]']              \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 16, 16,   1024       ['conv3d_2[0][0]']               \n",
      " rmalization)                   256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 16, 16, 16,   0           ['batch_normalization_1[0][0]']  \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 16, 16, 16,   0           ['leaky_re_lu_2[0][0]']          \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)              (None, 8, 8, 8, 512  8388608     ['dropout_2[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 8, 512  2048       ['conv3d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 8, 8, 8, 512  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)              (None, 8, 8, 8, 1)   32768       ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,079,168\n",
      "Trainable params: 11,077,376\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72173a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(inputs, filters, batchnorm=True):\n",
    "    g= Conv3D(filters, kernel_size=4, strides=2, padding=\"same\", \n",
    "                     kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), \n",
    "                     use_bias=False)(inputs)\n",
    "    if batchnorm:\n",
    "        g= BatchNormalization()(g)\n",
    "                                \n",
    "    g= LeakyReLU(0.2)(g)\n",
    "    g = Dropout(0.2)(g)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d1a605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, skips, filters, dropout=True):\n",
    "    g= Conv3DTranspose(filters, kernel_size=4, strides=2, padding=\"same\", \n",
    "                        kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), use_bias=False)(inputs)\n",
    "    g= BatchNormalization()(g)\n",
    "    g= LeakyReLU(0.3)(g)\n",
    "    g= Concatenate()([g, skips])\n",
    "    g=Dropout(0.2)(g)\n",
    "    \n",
    "    return g    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76b660b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottleneck(inputs, filters):\n",
    "    x= Conv3D(filters, kernel_size=4, strides=2, padding=\"same\", \n",
    "                     kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), \n",
    "                     use_bias=False)(inputs)\n",
    "    x=BatchNormalization()(x)\n",
    "    x= LeakyReLU(0.3)(x)\n",
    "    \n",
    "    for i in range(4):\n",
    "        y=Conv3D(filters, kernel_size=4, strides=1, padding=\"same\", \n",
    "                     kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), \n",
    "                     use_bias=False)(x)\n",
    "        x = BatchNormalization()(y)\n",
    "        x= LeakyReLU(0.3)(x)\n",
    "        x = Concatenate()([x, y])\n",
    "        print(x.shape)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff63f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    input_image=Input(shape=(128, 128, 128, 4))\n",
    "    \n",
    "    d1= encoder_block(input_image, 64, batchnorm=False) \n",
    "    print(d1.shape)\n",
    "    d2= encoder_block(d1, 128) \n",
    "    print(d2.shape)\n",
    "    d3= encoder_block(d2, 256) \n",
    "    print(d3.shape)\n",
    "    \n",
    "    \n",
    "    neck= bottleneck(d3, 512)#8x8x1024\n",
    "    \n",
    "    \n",
    "    u1= decoder_block(neck, d3, 256) \n",
    "    print(u1.shape)\n",
    "    u2 = decoder_block(u1, d2, 128) \n",
    "    print(u2.shape)\n",
    "    u3= decoder_block(u2, d1,64) \n",
    "    print(u3.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    final_conv= Conv3DTranspose(num_classes, kernel_size=4, strides=2, padding=\"same\", \n",
    "                        kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), use_bias=False)(u3)\n",
    "    print(final_conv.shape)\n",
    "    \n",
    "    out= Activation(\"softmax\")(final_conv)\n",
    "    print(out.shape)\n",
    "    return Model(input_image, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feda2c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 64, 64, 64)\n",
      "(None, 32, 32, 32, 128)\n",
      "(None, 16, 16, 16, 256)\n",
      "(None, 8, 8, 8, 1024)\n",
      "(None, 8, 8, 8, 1024)\n",
      "(None, 8, 8, 8, 1024)\n",
      "(None, 8, 8, 8, 1024)\n",
      "(None, 16, 16, 16, 512)\n",
      "(None, 32, 32, 32, 256)\n",
      "(None, 64, 64, 64, 128)\n",
      "(None, 128, 128, 128, 4)\n",
      "(None, 128, 128, 128, 4)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                28, 4)]                                                           \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)              (None, 64, 64, 64,   16384       ['input_3[0][0]']                \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 64, 64, 64,   0           ['conv3d_5[0][0]']               \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 64, 64, 64,   0           ['leaky_re_lu_4[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_6 (Conv3D)              (None, 32, 32, 32,   524288      ['dropout_3[0][0]']              \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 32,   512        ['conv3d_6[0][0]']               \n",
      " rmalization)                   128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 32, 32, 32,   0           ['batch_normalization_3[0][0]']  \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 32, 32, 32,   0           ['leaky_re_lu_5[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3d_7 (Conv3D)              (None, 16, 16, 16,   2097152     ['dropout_4[0][0]']              \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 16, 16,   1024       ['conv3d_7[0][0]']               \n",
      " rmalization)                   256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 16, 16, 16,   0           ['batch_normalization_4[0][0]']  \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 16, 16, 16,   0           ['leaky_re_lu_6[0][0]']          \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv3d_8 (Conv3D)              (None, 8, 8, 8, 512  8388608     ['dropout_5[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 8, 8, 8, 512  2048       ['conv3d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 8, 8, 8, 512  0           ['batch_normalization_5[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_9 (Conv3D)              (None, 8, 8, 8, 512  16777216    ['leaky_re_lu_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 8, 8, 8, 512  2048       ['conv3d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 8, 8, 8, 512  0           ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 8, 102  0           ['leaky_re_lu_8[0][0]',          \n",
      "                                4)                                'conv3d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_10 (Conv3D)             (None, 8, 8, 8, 512  33554432    ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 8, 8, 8, 512  2048       ['conv3d_10[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 8, 8, 8, 512  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 8, 8, 8, 102  0           ['leaky_re_lu_9[0][0]',          \n",
      "                                4)                                'conv3d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv3d_11 (Conv3D)             (None, 8, 8, 8, 512  33554432    ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 8, 8, 8, 512  2048       ['conv3d_11[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 8, 8, 8, 512  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 8, 8, 8, 102  0           ['leaky_re_lu_10[0][0]',         \n",
      "                                4)                                'conv3d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv3d_12 (Conv3D)             (None, 8, 8, 8, 512  33554432    ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 8, 8, 512  2048       ['conv3d_12[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 8, 8, 8, 512  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 8, 8, 8, 102  0           ['leaky_re_lu_11[0][0]',         \n",
      "                                4)                                'conv3d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv3d_transpose (Conv3DTransp  (None, 16, 16, 16,   16777216   ['concatenate_4[0][0]']          \n",
      " ose)                           256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 16,   1024       ['conv3d_transpose[0][0]']       \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 16, 16, 16,   0           ['batch_normalization_10[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 16, 16, 16,   0           ['leaky_re_lu_12[0][0]',         \n",
      "                                512)                              'dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 16, 16, 16,   0           ['concatenate_5[0][0]']          \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose_1 (Conv3DTran  (None, 32, 32, 32,   4194304    ['dropout_6[0][0]']              \n",
      " spose)                         128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 32, 32, 32,   512        ['conv3d_transpose_1[0][0]']     \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 32, 32, 32,   0           ['batch_normalization_11[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 32, 32, 32,   0           ['leaky_re_lu_13[0][0]',         \n",
      "                                256)                              'dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 32, 32, 32,   0           ['concatenate_6[0][0]']          \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose_2 (Conv3DTran  (None, 64, 64, 64,   1048576    ['dropout_7[0][0]']              \n",
      " spose)                         64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 64, 64, 64,   256        ['conv3d_transpose_2[0][0]']     \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 64, 64, 64,   0           ['batch_normalization_12[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 64, 64, 64,   0           ['leaky_re_lu_14[0][0]',         \n",
      "                                128)                              'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 64, 64, 64,   0           ['concatenate_7[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose_3 (Conv3DTran  (None, 128, 128, 12  32768      ['dropout_8[0][0]']              \n",
      " spose)                         8, 4)                                                             \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 128, 128, 12  0           ['conv3d_transpose_3[0][0]']     \n",
      "                                8, 4)                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 150,533,376\n",
      "Trainable params: 150,526,592\n",
      "Non-trainable params: 6,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92371599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c9f015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalized_dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-5  # Smoothing factor to avoid division by zero\n",
    "    \n",
    "    # Flatten the true and predicted tensors\n",
    "    y_true_flat = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_flat = tf.keras.backend.flatten(y_pred)\n",
    "    \n",
    "    # Compute the weights for each class based on inverse of class frequency\n",
    "    weights = 1.0 / (tf.reduce_sum(y_true_flat, axis=0)**2 + smooth)\n",
    "    # Compute the intersection and sum of true and predicted tensors\n",
    "    intersection = weights*(tf.reduce_sum(y_true_flat * y_pred_flat, axis=0))\n",
    "    intersection= tf.reduce_sum(intersection)\n",
    "    \n",
    "    sum_true = tf.reduce_sum(y_true_flat, axis=0)\n",
    "    sum_pred = tf.reduce_sum(y_pred_flat, axis=0)\n",
    "    union=tf.reduce_sum(weights*(sum_true+sum_pred))\n",
    "    \n",
    "    # Compute the dice coefficient for each class\n",
    "    dice_coefficient = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    generalized_dice_loss= 1- dice_coefficient\n",
    "    return generalized_dice_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f43abd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator loss ###L2 loss between real and fake outputs\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = tf.reduce_mean(tf.math.pow(tf.ones_like(disc_real_output)- disc_real_output,2))\n",
    "    fake_loss = tf.reduce_mean(tf.math.pow(tf.zeros_like(disc_generated_output)- disc_generated_output,2))\n",
    "    total_disc_loss = 0.5*(real_loss + fake_loss)\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1816b88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator loss\n",
    "def generator_loss(disc_generated_output, generated_images, target):\n",
    "    gan_loss= tf.reduce_mean(tf.math.pow(tf.ones_like(disc_generated_output)-disc_generated_output,2))\n",
    "    dice_loss= generalized_dice_loss(target, generated_images)\n",
    "    total_gen_loss= 5*dice_loss + gan_loss\n",
    "\n",
    "    return total_gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0efe2174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 64, 64, 64)\n",
      "(None, 32, 32, 32, 128)\n",
      "(None, 16, 16, 16, 256)\n",
      "(None, 8, 8, 8, 1024)\n",
      "(None, 8, 8, 8, 1024)\n",
      "(None, 8, 8, 8, 1024)\n",
      "(None, 8, 8, 8, 1024)\n",
      "(None, 16, 16, 16, 512)\n",
      "(None, 32, 32, 32, 256)\n",
      "(None, 64, 64, 64, 128)\n",
      "(None, 128, 128, 128, 4)\n",
      "(None, 128, 128, 128, 4)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate generator and discriminator\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e50fd0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "generator_optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5, beta_2=0.999)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9e8dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # Generate fake image\n",
    "        generated_images = generator(input_image, training=True)\n",
    "\n",
    "        # Discriminator outputs\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, generated_images], training=True)\n",
    "\n",
    "        # Calculate losses\n",
    "        gen_total_loss = generator_loss(disc_generated_output, generated_images, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    # Calculate gradients\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # Apply gradients\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
    "    return gen_total_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10168df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=50\n",
    "total_images = 275\n",
    "steps_per_epoch = total_images // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cff9ff2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 275/275 [05:12<00:00,  1.14s/it, Generator Loss=0.45, Discriminator Loss=0.325] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 275/275 [05:04<00:00,  1.11s/it, Generator Loss=0.426, Discriminator Loss=0.39] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 275/275 [05:03<00:00,  1.10s/it, Generator Loss=1.71, Discriminator Loss=0.93]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 275/275 [05:05<00:00,  1.11s/it, Generator Loss=0.67, Discriminator Loss=0.24]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 275/275 [05:05<00:00,  1.11s/it, Generator Loss=0.951, Discriminator Loss=0.108] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 275/275 [05:04<00:00,  1.11s/it, Generator Loss=0.678, Discriminator Loss=0.182] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 275/275 [05:03<00:00,  1.10s/it, Generator Loss=1.26, Discriminator Loss=0.146]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 275/275 [05:14<00:00,  1.14s/it, Generator Loss=0.505, Discriminator Loss=0.148] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 275/275 [05:08<00:00,  1.12s/it, Generator Loss=0.633, Discriminator Loss=0.12]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 275/275 [05:04<00:00,  1.11s/it, Generator Loss=0.456, Discriminator Loss=0.195] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 275/275 [05:20<00:00,  1.17s/it, Generator Loss=0.387, Discriminator Loss=0.28]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 275/275 [05:12<00:00,  1.13s/it, Generator Loss=0.498, Discriminator Loss=0.174] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 275/275 [05:12<00:00,  1.14s/it, Generator Loss=0.438, Discriminator Loss=0.131] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 275/275 [05:16<00:00,  1.15s/it, Generator Loss=0.277, Discriminator Loss=0.265] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 275/275 [05:16<00:00,  1.15s/it, Generator Loss=0.207, Discriminator Loss=0.317] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 275/275 [05:15<00:00,  1.15s/it, Generator Loss=0.323, Discriminator Loss=0.307] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 275/275 [05:09<00:00,  1.13s/it, Generator Loss=0.871, Discriminator Loss=0.188] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 275/275 [05:08<00:00,  1.12s/it, Generator Loss=0.453, Discriminator Loss=0.23]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 275/275 [05:10<00:00,  1.13s/it, Generator Loss=0.604, Discriminator Loss=0.223] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 275/275 [04:59<00:00,  1.09s/it, Generator Loss=1.31, Discriminator Loss=0.46]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 275/275 [05:05<00:00,  1.11s/it, Generator Loss=0.187, Discriminator Loss=0.236] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 275/275 [05:01<00:00,  1.10s/it, Generator Loss=0.254, Discriminator Loss=0.304] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 275/275 [05:02<00:00,  1.10s/it, Generator Loss=0.162, Discriminator Loss=0.249] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 275/275 [05:03<00:00,  1.11s/it, Generator Loss=0.273, Discriminator Loss=0.245] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 275/275 [05:04<00:00,  1.11s/it, Generator Loss=0.254, Discriminator Loss=0.276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 275/275 [05:01<00:00,  1.10s/it, Generator Loss=0.245, Discriminator Loss=0.27] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 275/275 [05:02<00:00,  1.10s/it, Generator Loss=0.336, Discriminator Loss=0.232] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 275/275 [05:03<00:00,  1.10s/it, Generator Loss=0.308, Discriminator Loss=0.236] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 275/275 [05:04<00:00,  1.11s/it, Generator Loss=0.448, Discriminator Loss=0.196] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 275/275 [05:02<00:00,  1.10s/it, Generator Loss=0.353, Discriminator Loss=0.232] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 275/275 [05:03<00:00,  1.10s/it, Generator Loss=0.457, Discriminator Loss=0.1]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 275/275 [05:02<00:00,  1.10s/it, Generator Loss=0.293, Discriminator Loss=0.246] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 275/275 [05:02<00:00,  1.10s/it, Generator Loss=0.237, Discriminator Loss=0.426] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 275/275 [05:04<00:00,  1.11s/it, Generator Loss=0.978, Discriminator Loss=0.371] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 275/275 [04:58<00:00,  1.08s/it, Generator Loss=0.712, Discriminator Loss=0.255] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 275/275 [05:43<00:00,  1.25s/it, Generator Loss=0.545, Discriminator Loss=0.199] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 275/275 [05:01<00:00,  1.10s/it, Generator Loss=0.919, Discriminator Loss=0.182] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 275/275 [05:01<00:00,  1.10s/it, Generator Loss=0.777, Discriminator Loss=0.0778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 275/275 [05:02<00:00,  1.10s/it, Generator Loss=0.443, Discriminator Loss=0.306] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 275/275 [05:03<00:00,  1.10s/it, Generator Loss=0.29, Discriminator Loss=0.326]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 275/275 [05:03<00:00,  1.10s/it, Generator Loss=0.198, Discriminator Loss=0.253] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 275/275 [05:01<00:00,  1.09s/it, Generator Loss=0.401, Discriminator Loss=0.124] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 275/275 [05:00<00:00,  1.09s/it, Generator Loss=0.889, Discriminator Loss=0.215] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 275/275 [04:59<00:00,  1.09s/it, Generator Loss=0.327, Discriminator Loss=0.32]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 275/275 [04:59<00:00,  1.09s/it, Generator Loss=0.119, Discriminator Loss=0.399] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 275/275 [04:59<00:00,  1.09s/it, Generator Loss=0.365, Discriminator Loss=0.154] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 275/275 [04:58<00:00,  1.09s/it, Generator Loss=0.253, Discriminator Loss=0.287] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 275/275 [05:00<00:00,  1.09s/it, Generator Loss=0.796, Discriminator Loss=0.294] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 275/275 [04:58<00:00,  1.08s/it, Generator Loss=0.379, Discriminator Loss=0.209] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 275/275 [04:58<00:00,  1.08s/it, Generator Loss=0.512, Discriminator Loss=0.227] \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch:\", epoch+1)\n",
    "    \n",
    "    # Create a progress bar for the training dataset\n",
    "    progress_bar = tqdm(range(steps_per_epoch), desc=f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    # Iterate over the training dataset\n",
    "    for step in progress_bar:\n",
    "        # Get the next batch of input and target images\n",
    "        input_images, target_images = next(train_dataset)\n",
    "        \n",
    "        # Perform a single training step\n",
    "        gen_loss, disc_loss = train_step(input_images, target_images)\n",
    "        \n",
    "        # Update the progress bar description with the current losses\n",
    "        progress_bar.set_postfix({\"Generator Loss\": gen_loss.numpy(), \"Discriminator Loss\": disc_loss.numpy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7414e5a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: generator50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: generator50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: discriminator50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: discriminator50\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the trained generator model\n",
    "from tensorflow.keras.models import save_model\n",
    "# Save the trained generator model\n",
    "generator.save(\"generator50\")\n",
    "# Save the trained discriminator model\n",
    "discriminator.save(\"discriminator50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b261cae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c300674c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87bd04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf611120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addefd1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fde828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
